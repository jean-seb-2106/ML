---
title: "Tuto Machine learning sous R"
author: "Cefil-2024"
date: "27/06/2024"
format: 
  html:
    toc: true
    toc-depth: 4
    number-sections: true
    code-fold: false
    df-print: paged
editor: visual
embed-resources: true
---

En complément du corrigé des exercices, voici le code R sous-jacent à Asta, afin que vous puissiez produire ou appliquer les méthodes de machine learning directement sous R.

C'est le package `tidymodels` qui est utilisé dans ASTA pour faire du machine learning. Il regroupe et intègre les packages r suivants :`rsample`, `recipes`, `tune`, `parnsnip`, `yardstick`... Chacun de ces packages étant utile pour le machine learning.

Par ailleurs, on utilise le package `skimr` pour explorer les fichiers.

Les données de l'exercice sont intégrées au package ASTA. On distingue les deux grands types d'apprentissage automatique :

-   la classification supervisée

-   la régression supervisée.

L'application ASTA ne permet pas de paramétrer les différents modèles : ces paramètres sont définis par défaut dans l'application. Elle ne permet pas non plus de faire de la validation croisée (qui est d'usage en machine learning) ni d'optimiser chaque modèle pour trouver les meilleurs hyper-paramètres.

```{r}
#| message: false
#| warning: false
# install.packages("tidymodels")
# install.packages("skimr")
#install.packages("glmnet")
library(tidymodels)
library(skimr)
library(glmnet)
```

## Classification supervisée

```{r}
#| message: false
#| warning: false
library(asta)
data <- asta::vins %>% rename(target = quality)
# data <- asta::grandile %>% rename(target = PAUVRE) %>%
#   select(-starts_with("LIB")) %>%
#   select(-IDENT) %>%
#   mutate(target = as.factor(target))
```

Les deux fichiers utilisés pour faire de la classification dans `asta`. On fait quelques modifications sur ces fichiers pour faire en sorte que la variable à expliquer ait le même nom dans les deux fichiers (`target`).

### Exploration de la base brute

```{r}
skim(data)
```

### Partitionnement de la base brute

La base intiale est découpée en trois bases :

-   base d'entraînement

-   base de validation

-   base de test

Il est possible d'utiliser une variable de stratification (souvent la variable à expliquer) pour que les 3 bases aient suffisament d'individus du même type. Les fonctions utilisées sont issues du package `rsample`.

```{r}
#Paramétrage des parts pour chaque base. 
part_training <- 0.7 #70% pour l'entraînement
part_validation <- 0.15 #15% pour la validation


#on contrôle l'aléatoire pour avoir toujours la même base.
set.seed(1234)

#le paramètre strata permet de garder la même proportion de la variable dans les trois bases.
data_split <- initial_validation_split(data,
                                       strata = target, 
                                       prop = c(part_training,part_validation)
                                       )

#La dernière base est la base d'entraînement et la base de validation.
train_data <- training(data_split) 
test_data <- testing(data_split) 
valid_data <- validation(data_split)
train_valid_data <- train_data %>% bind_rows(valid_data)
```

### Modifications de la base

C'est le package `recipes` qui est utilisé ici pour faire des modifications sur les bases (du preprocessing) qui peuvent être de nombreux types :

-   ajout/suppresion de variables

-   transformation de variable (log, exponentielle..)

-   imputation des données manquantes (plusieurs méthodes)

-   filtrage d'individus

-   encodage (one hot par exemple..)

Ces modifications sont parfois nécessaires pour que les modèles puissent marcher (par exemple, la forêt aléatoire ne peut pas s'ajuster sur une base avec des données manquantes). Mais elles peuvent aussi permettre d'améliorer la qualité du modèle.

Il y a certaines transformations qui sont automatiquement appliquées aux bases de données par les modèles.

Le package `recipes` permet ainsi de tester plusieurs versions de la base (plusieurs recettes appliquées à la base) sur lesquelles on ajustera un même modèle.

<https://recipes.tidymodels.org/reference/index.html#basic-functions>

```{r}

#choisir les recettes qu'on applique à la base, avec des step
rec <- 
  recipe(target ~ ., data = train_data) %>% 
  step_normalize(all_numeric_predictors()) #%>% 
  # step_rm() #supprimer des variables # %>% 
#  step_dummy(all_nominal_predictors()) %>% #: transformer les variables nominales en indicatrices
# %>% update_role(flight, time_hour, new_role = "ID") %>% #: retirer des variables du modèle, mais les laisser en affichage
# %>% step_zv() #pour enlever les variables avec une seule valeur

# %>% step_impute_mode() #imputation des valeurs manquantes avec le mode
# %>% step_impute_mean() #imputation des valeurs manquantes avec la moyenne
# %>% step_clean_names #nettoyer le nom des variables
# %>% step_log #ajouter une variable de type logarithme
# %>% step_filter #pour filtrer la base en utilisant dplyr
# %>% step_mutate #pour créer une nouvelle variable en utilisant dplyr
```

Cette base modifiée peut-être visualisée à l'aide des fonctions contenues dans le package `recipes`.

```{r}
recette <- prep(rec) #Je prépare la recette
data_modifie <- bake(recette,new_data = NULL) #Je l'appplique par défaut sur la base définie dans la fonction recipe
skim(data_modifie)
```

### Choix d'un modèle

Les modèles utilisés viennent du package `parnsnip.`

-   La régression logistique

```{r}
mod_lr <- 
  logistic_reg() %>% 
  set_engine("glm")
```

-   L'arbre de classification

```{r}
mod_tree <- 
  decision_tree(
    cost_complexity = 0.001, #hyper-paramètre mesurant la complexité de l'arbre
    tree_depth = 7, #pour paramétrer la profondeur de l'arbre
    min_n = NULL #nombre minimum d'individus dans un noeud pour être divisé
  ) %>%
  set_engine("rpart") %>% #méthode d'estimation
  set_mode("classification")
```

-   la forêt aléatoire

    ```{r}
    mod_rf <- 
      rand_forest(trees = 1000, #nombre d'arbres
                  mtry = 3, #nombre de variables
                  min_n = NULL) %>% #nombre minimum d'individus dans un noeud pour être divisé
      set_engine("ranger") %>% 
      set_mode("classification")
    ```

-   le KNN : plus proches voisins

    ```{r}
    mod_knn <- 
      nearest_neighbor(
        neighbors = 3 #nombre de voisins
      ) %>% 
      set_engine("kknn") %>% 
      set_mode("classification")
    ```

-   le SVM (support vector machine)[^1]

    ```{r}
    mod_svm <- 
      svm_rbf(mode = "classification", 
                         cost = 10, 
                         rbf_sigma = 0.1, 
                         margin = 1) %>%
      set_engine("kernlab")
    ```

-   La régression ridge[^2]

    ```{r}
    mod_ridge <- 
      logistic_reg(penalty = 0.01, #hyper-paramètre  
                   mixture = 0) %>% 
      set_engine("glmnet")

    ```

-   la régression lasso[^3]

    ```{r}
    mod_lasso <- 
      logistic_reg(penalty = 0.001, #hyper-paramètre
                   mixture = 1) %>% 
      set_engine("glmnet")

    ```

[^1]: modèle non proposé dans ASTA

[^2]: Modèle qui n'est pas proposé dans ASTA

[^3]: modèle non proposé dans ASTA

### Création d'un workflow

Un workflow dans ce cas est une recette appliquée à une base (la base d'entraînement) et un modèle.

```{r}
mod <- mod_rf

wflow <-  workflow() %>% 
  add_model(mod) %>% #ajout du modèle
  add_recipe(rec) #ajout de la recette (transfo de la base initiale)
wflow
```

### Ajustement du modèle

C'est à cette étape que le modèle s'ajuste sur les données d'entraînement, c'est à dire que l'algorithme trouve le modèle qui estime le mieux. La fonction `fit` génère une instance du modèle qui a été entraîné sur la base d'entraînement.

```{r}
fit <- wflow %>% fit(data=train_data)
extract_fit_parsnip(fit)
```

On peut visualiser les estimations de ce modèle sur la base d'entraînement. A chaque classe de la variable target est associée une probabilité : si elle est supérieure à 0,5, alors c'est cette modalité qui est estimée par le modèle.

```{r}
augment(fit,train_data) %>% select(target,starts_with(".pred")) %>% head(10)
```

### Performance du modèle

L'instance du modèle généré à l'étape précédente est appliquée à la base de validation, qui n'a pas servi à ajuster le modèle. Autrement dit, ce sont des données que le modèle n'a jamais vu et qui vont permettre d'évaluer les capacités prédictives de notre modèle.

```{r}
pred_valid <- augment(fit, valid_data) %>% select(target,starts_with(".pred"))
pred_valid
```

A partir de ce tableau de prédiction sur la base de validation, je peux construire un tableau de confusion, qui classe chaque individu de la base de validation dans une des 4 cases du tableau : VP (vrai positif), FP (faux positif), VN (vrai négatif), FN (faux négatif).

```{r}
pred_valid %>%
  conf_mat(target, .pred_class) %>%
  autoplot(type="heatmap")
```

A partir de ce tableau de confusion, on peut définir des indicateurs de performance et la courbe ROC. Les fonctions permettant de calculer les performances sont dans le package `yardstick`.

```{r}
accuracy <- pred_valid %>% 
  accuracy(truth = target, .pred_class) %>% 
  select(.estimate) %>% 
  as.numeric() %>% 
  round(2)

specificity <- pred_valid %>% 
  specificity(truth = target, .pred_class) %>% 
  select(.estimate) %>% 
  as.numeric() %>% 
  round(2)

sensitivity <- pred_valid %>% 
  sensitivity(truth = target, .pred_class) %>% 
  select(.estimate) %>% 
  as.numeric() %>% 
  round(2)
```

| Modèle            | Recette                       | Accuracy     | Spécificité     | Sensibilité     |
|-------------------|-------------------------------|--------------|-----------------|-----------------|
| `r class(mod)[1]` | `r class(recette$steps[[1]])` | `r accuracy` | `r specificity` | `r sensitivity` |

On peut aussi calculer l'AUC et dessiner la courbe ROC.

```{r}
pred1 <- names(pred_valid)[3]
roc_plot_valid <- pred_valid %>% 
  roc_curve(truth = target,all_of(pred1)) %>% 
  autoplot()
roc_plot_valid
```

### Ajustement du modèle final

Le modèle final (celui qui a la meilleure performance) est ajusté sur la base d'entraînement et la base de validation. C'est cette instance de modèle qui sera utilisé pour faire des prédictions sur des individus qui n'ont jamais été vus par le modèle.

```{r}
fit_final <-
  wflow %>% fit(train_valid_data)
pred_final <- augment(fit_final,test_data)

accuracy <- pred_final %>% 
  accuracy(truth = target, .pred_class) %>% 
  select(.estimate) %>% 
  as.numeric() %>% 
  round(2)

specificity <- pred_final %>% 
  specificity(truth = target, .pred_class) %>% 
  select(.estimate) %>% 
  as.numeric() %>% 
  round(2)

sensitivity <- pred_final %>% 
  sensitivity(truth = target, .pred_class) %>% 
  select(.estimate) %>% 
  as.numeric() %>% 
  round(2)
```

| Modèle            | Recette                       | Accuracy     | Spécificité     | Sensibilité     |
|-------------------|-------------------------------|--------------|-----------------|-----------------|
| `r class(mod)[1]` | `r class(recette$steps[[1]])` | `r accuracy` | `r specificity` | `r sensitivity` |

## Régression supervisée
