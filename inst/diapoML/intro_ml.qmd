---
title: "Introduction au machine learning"
author: "Attachés 2024"
format: 
  revealjs:
    incremental: true
    embed-resources: true #pour tout mettre dans un seul fichier
    scrollable: true
    theme: serif
editor: visual
---

```{r}
library(kableExtra)
library(dplyr)
library(asta) #pour récupérer la base titanic
library(skimr)
library(tidymodels)
library(rpart.plot)
```

## Vous avez dit "machine learning" ?

![](IA_ML.png){fig-align="center"}

::: notes
L'intelligence artificielle définie par Yann le Cun [@Cun2019] : *l'intelligence artificielle est la capacité pour une machine d'assurer des tâches généralement assurée par les animaux ou les humains : percevoir, raisonner, agir.*

Le machine learning fait partie d'intelligence artificielle, mais il se distingue de l'IA historique par son mode de fonctionnement.

Le deep learning est un machine learning très puissant, utilisé sur des données très volumineuses (images, vidéos..) et nécessitant de grosses puissances de calculs.
:::

## "La bonne vieille IA"...

![](système_expert.png){fig-align="center"}

::: notes
Il y a "la bonne vieille intelligence artificielle" en français, celle pour laquelle un expert explicite toutes les règles qui sont ensuite traduites en langue informatique. Il faut l'expert à côté de l'informaticien qui code, pour lui donner toutes les règles.

C'est celle qu'on utilise depuis longtemps, depuis les années 50.
:::

## ...VS l'apprentissage automatique

![](machine-learning-entrainement-ia.jpg){fig-align="center"}

::: notes
Avec le machine learning, on donne à la machine une grande quantité de donnée, et elle va trouver 'toute seule' cette règle, c'est pour ça qu'on dit qu'elle apprend. Elle apprend grace à un algorithme qui permet de traiter une (très) grande quantité de donnée pour en faire ressortir un schéma réccurent.
:::

<!-- ## et le Deep learning -->

<!-- ![](reseau_neurones.jpg){fig-align="center"} -->

<!-- ::: notes -->

<!-- Le deep learning est un sous domaine du machine learning : globalement, il veut reproduire le cerveau humain grace à des neurones articifiels. très puissant en reconnaissance d'images par exemple. -->

<!-- ::: -->

## Les différents types d'apprentissage automatique

1.  L'apprentissage supervisé

2.  L'apprentissage non supervisé

3.  L'apprentissage par essai/erreur

::: notes
Dans ce module d'introduction, on va principalement étudier l'apprentissage supervisé. L'apprentissage non supervisé a été vu en partie dans le module sur la modélisation. Enfin, le dernier type d'apprentissage ne sera pas vu, c'est celui qui est utilisé pour simuler un joueur de jeu de go ou d'échec par exemple.

la différence entre supervisé et non supervisé est dans la diapo suivante.
:::

------------------------------------------------------------------------

![](supervisé_nonsupervisé.png){fig-align="center"}

::: notes
Dans le non supervisé, les données ne sont pas étiquetés. Le but pour la machine est de détecter les ressemblances entre les individus (cf module sur le clustering).

Dans le supervisé, la machine apprend sur des données étiquetés (avec un Y). L'image a un nom, et le but est de faire en sorte que le modèle soit capable de prédire correctement une nouvelle image.

Cette image vient du site suivant :

<https://www.le-cortex.com/media/articles/lintelligence-artificielle-comment-ca-marche>
:::

## But de l'apprentissage supervisé : la prédiction {.smaller}

::: columns
::: {.column width="50%"}
-   $$
    Y = f(X_1, X_2, ...,X_n)
    $$

-   Le but premier n'est pas d'expliquer mais de prédire.

-   Deux types d'apprentissage supervisé selon Y.
:::

::: {.column width="50%"}
![](42293349-photo-de-future-femme-prédiction-de-la-boule-de-cristal.jpg)
:::
:::

::: notes
-   Il s'agit de trouver la fonction f qui va le mieux **prédire** Y en fonction de X1, X2...,Xn

-   On distingue la modélisation statistique (cf module 3 de statistique), avec des tests et des hypothèses. Le but est d'expliquer, d'interpréter, de comprendre les données du machine learning, qui a pour objectif d'avoir les meilleures performances prédictives, au détriment parfois de l'interprétabilité.
:::

---

![](types_apprentissage.png){fig-align="center"}

::: notes
Attention : en machine learning, dans un problème de régression (Y est quanti continu), je n'utilise pas nécessairement la régression linéaire (qui est un modèle parmi d'autres) comme modèle. Dans un problème de classification (Y est quali), je peux utiliser une régression logistique comme modèle pour apprendre.
:::

## Prédire ou estimer ?

::: panel-tabset
## Base de départ

```{r}
locations <- data.frame(Y_prix = c(1000,800,600,1000,800),X1_surface = c(50,30,25,60,35))
row.names(locations) <- c("logement1","logement2","logement3","logement4","logement5")
kbl(locations,
    format = "html")
```

## Modèle

```{r}
reg <- lm(locations$Y_prix ~ locations$X1_surface)
```

$$
Y = 416,5 + 10,6 X_1
$$

## Estimations

```{r}

locations$prix_estime <- predict(reg) %>% round(1)
kbl(locations,
    format = "html")
```

## Prévisions

```{r}
locations <- data.frame(surface = c(45,30,110))
row.names(locations) <- c("logement6","logement7","logement8")



locations <- locations %>% 
  mutate(prix_prevu = reg$coefficients[1] + reg$coefficients[2]*surface) %>% round(1)
kbl(locations,format = "html")

```
:::

::: notes
On cherche à prédire le prix d'un logement en fonction de sa surface. J'ai une base de données de 5 logements étiquetés (avec le prix) et une variable explicative (la surface). Il s'agit donc d'un problème de régression (et pas de classification).
:::

## Comment la machine apprend ? {.nonsmaller}

-   La machine apprend sur des données étiquetées grâce à des algorithmes/modèles.

-   Le but de ces algorithmes est de minimiser [l'erreur d'estimation]{.underline}.

-   Ces algorithmes (très nombreux!) sont spéficiques pour les deux types d'apprentissage (classification et régression).

::: notes
Un algorithme est une série d'instructions définies et ordonnées qui permettent d'effectuer une tâche spécifique. Il existe plusieurs façons d'évaluer l'erreur d'estimation, certaines ont déjà été vues pendant le TD sur les régressions. L'erreur quadratique est un exemple d'erreur d'estimation que l'algorithme de la régression cherche à estimer.
:::

------------------------------------------------------------------------

::: columns
::: {.column width="50%"}
[**Régression supervisé**]{.underline}

-   Régression linéaire

-   Arbre de régression

-   Forêt aléatoire

-   XGBoost

-   KNN

-   SVM
:::

::: {.column width="50%"}
[**Classification supervisé**]{.underline}

-   Régression logistique

-   Arbre de classification

-   Forêt aléatoire

-   XGBoost

-   KNN

-   SVM
:::
:::






## Comment savoir si un modèle est performant ?

::: columns
::: {.column width="50%"}
![](entraînement_test.png)
:::

::: {.column width="50%"}
-   Le modèle apprend (s'ajuste) sur une base d'entraînement.

-   Un modèle entraîné sur une base s'appelle une instance.

-   On teste la performance de cette instance sur une base de validation.
:::
:::

## Problème de régression {.smaller}

::: panel-tabset
## Base Brute

```{r}
locations <- data.frame(Y_prix = c(1000,800,600,1000,800,900,300,1500),X1_surface = c(50,30,25,60,35,45,30,110))
row.names(locations) <- c("logement1","logement2","logement3","logement4","logement5","logement6","logement7","logement8")
kbl(locations,
    format = "html",caption = "locations")
```

## Base d'entraînement

```{r}
locations_train <- data.frame(Y_prix = c(1000,800,600,1000,800),X1_surface = c(50,30,25,60,35))
row.names(locations_train) <- c("logement1","logement2","logement3","logement4","logement5")
kbl(locations_train,
    format = "html",caption="location_train")
```

## Apprentissage

```{r}
reg <- lm(locations_train$Y_prix ~ locations_train$X1_surface)
summary(reg)



```

## Base de validation

```{r}
locations_valid <- locations[6:8,]

#workflow sur la base d'entraînement
rec <- recipe(Y_prix ~ ., data = locations_train) #aucune recette appliquée
mod_lr <- linear_reg() %>% 
  set_engine("lm")
wflow <- workflow() %>% 
  add_recipe(rec) %>% 
  add_model(mod_lr)

#ajustement sur la base d'entraînement
fit_lr <- wflow %>% fit(data=locations_train)

#Prédiction sur la base de validation
pred <- augment(fit_lr, locations_valid) #%>% select(-`.resid`) %>% rename(Y_REG = `.pred`)
row.names(pred) <- c("logement6","logement7","logement8")

kbl(pred,digits=c(1,1,0,0),caption = "locations_valid")
```
:::

## Indicateurs de performances

$$                                        
 RSS = \sum_{i=1}^{N}{(y_i - \hat{y}_i)^2} 
 $$

$$                                        
 MSE = \frac{RSS}{N}                     
 $$

$$                                                     
                                             RMSE = \sqrt{MSE}                                   
                                             $$

$$                                                     
                                             R² = \frac{SCE}{SCT}  
                                             $$

::: notes
Les valeurs des indicateurs de performance donnent une première idée de la qualité du modèle en matière de prédiction (on voit notamment que le coeff de détermination est très faible). Mais la vraie utilité, c'est pour comparer plusieurs modèles entre eux : on verra un exemple plus bas.\

RSS = 7,1² + 434,1² + 81,2² = 195 087 MSE = 65 029 RMSE = 255 R² = 0.18
:::

## Problème de classification {.smaller}

::: panel-tabset
## Base Brute

```{r}
canards <- data.frame(Y_femelle = c("1","1","0","1","1","0","0","0","1","0"),X1_poids = c(841,600,1200,500,700,1150,750,800,680,910)) %>% mutate(Y_femelle = as.factor(Y_femelle))
row.names(canards) <- c("canard1","canard2","canard3","canard4","canard5","canard6","canard7","canard8","canard9","canards10")
kbl(canards,
    format = "html",caption = "canards")
```

## Base d'entraînement

```{r}
canards_train <- canards[1:7,]
row.names(canards_train) <- c("canard1","canard2","canard3","canard4","canard5","canards6","canards7")
kbl(canards_train,
    format = "html",
caption="canards_train")
```

## Apprentissage

```{r}


#workflow sur la base d'entraînement
rec <- recipe(Y_femelle ~ ., data = canards_train) 

mod_lr <- 
  logistic_reg() %>% 
  set_engine("glm")
wflow <- workflow() %>% 
  add_recipe(rec) %>% 
  add_model(mod_lr)

#ajustement sur la base d'entraînement
fit_lr <- wflow %>% fit(data=canards_train)
fit_lr


```

## Base de validation

```{r}

canards_valid <- canards[8:10,]

#Prédiction sur la base de validation
pred <- augment(fit_lr, canards_valid) #%>% select(-`.resid`) %>% rename(Y_REG = `.pred`)
row.names(pred) <- c("canards8","canards9","canards10")

kbl(pred,digits=c(1,2,2,0,0),caption = "canards_valid",centering = TRUE)
```
:::

## Indicateurs de performances {.smaller}

```{r}
# pred %>%
#   conf_mat(Y_sexe, .pred_class) %>%
#   autoplot(type="heatmap")
```

![](matrice_de_confusion.png){fig-align="left"}

**Exactitude** : (TN + TP) / (TN + TP + FP + FN)

**Sensibilité (Rappel)** : TP / (TP + FN)

**Spécificité** : TN / (TN + FP)

**Précision** : TP / (TP + FP)

## Les deux écueils de l'apprentissage {.smaller}

-   **Le sous-apprentissage** : le modèle n'est pas adapté ou trop simple.

-   **Le sur-apprentissage** : le modèle colle trop aux données d'apprentissage.

------------------------------------------------------------------------

::: panel-tabset
## Sous-Apprentissage

![](sous_apprentissage.png){fig-align="center" width="500"}

## Bon modèle

![](apprentissage_adapté.png){fig-align="center" width="500"}

## Sur-apprentissage

![](sur-apprentissage.png){fig-align="center" width="500"}
:::

::: notes
Un modèle qui apprend correctement ne doit ni être trop simple ni trop complexe. si il est trop simple, il prédira probablement mal (puisqu'il estime mal). Si il est trop complexe, il colle trop aux données ayant servi à construire le modèle, et donc il ne va pas bien marcher avec de nouvelles données.

Le but est de prédire la couleur des points (orange ou bleu), c'est donc un problème de classification supervisée :

-   dans le premier cas, le modèle est trop simple : il va mal estimer et il va mal prédire (trop de biais)

-   Dans le deuxième cas, le modèle est trop complexe : il va bien estimer mais il risque de mal prédire

-   Dans le dernier cas, l'estimation est correcte (même si elle est moins bonne que dans le cas précédent) mais la prévision risque d'être meilleure, parce qu'elle colle moins aux données.
:::

## Le compromis biais-variance

![](biais_variance.png){fig-align="center"}

## Autre exemple

![](sur_sous_apprentissage.PNG){fig-align="left"}


## Un exemple d'arbre de décision

![](Exemple-darbre-de-regression.png){.smaller fig-align="center" width="400"}


## Les arbres de décision, comment ça marche ?

L'algorithme CART permet d'ajuster le modèle sur les données d'entraînement.

1.  A chaque noeud, l'algorithme (CART) choisit la variable la plus discriminante

2.  Il teste toutes les valeurs de cette variable et choisit celle qui estime le mieux

3.  Partage de la population en deux noeuds.

4.  L'estimation est la moyenne

::: notes
CART : classifications and regression trees. C'est l'algorithme le plus utilisé, il est adapté à régression et la classification. Il en existe d'autres.

Pour tout savoir sur les arbres de régression (et de classification) :

<https://blent.ai/blog/a/arbres-de-decision-en-machine-learning>
:::


## Les étapes de l'apprentissage supervisé :

1.  Définir le sujet (classification ou régression ?)

2.  Explorer et nettoyer la base de données

3.  Réserver une partie de la base pour l'apprentissage/test

4.  Apprendre des données avec des modèles/algorithmes

5.  Comparer les performances prédictives de ces algorithmes

6.  Choisir le meilleur modèle et le mettre en production

# Premier exemple

## Régression ou classification ?

```{r}
grandile <- asta::grandile %>% 
select(Y_REVENU = REV_DISPONIBLE, X1_NBPIECES= NBPIECES,X2_AGE = AGE)
kbl(head(grandile),caption="Grandile")
```

## Exploration de la base brute {.scrollable}

```{r}
summary(grandile)
# skim(grandile)
```

## Nettoyage et transformation des données

-   Traitement des données manquantes

-   Traitement des "outliers"

-   Encodage de variables

-   Transformation de variables (log, centrage-réduction)

-   Création de nouvelles variables

## Partition de la base

![](training-validation-test-sets.png){fig-align="center"}

-   Base d'entraînement : 60 %

-   Base de validation : 20 %

-   Base de test : 20 %

## Base d'entraînement {.scrollable}

```{r}
part_training <- 0.6 
part_validation <- 0.2
set.seed(1234)

grandile_split <- initial_validation_split(grandile,prop = c(part_training,part_validation))

train_grandile <- training(grandile_split) #le fichier d'entraînement
test_grandile <- testing(grandile_split) #le fichier de test
valid_grandile <- validation(grandile_split)
train_valid_grandile <- train_grandile %>% bind_rows(valid_grandile)
```

```{r}
# skim(train_grandile)
summary(train_grandile)
```

::: notes
Dans ce cas, il s'agit d'un tirage aléatoire simple. Donc la base d'entraînement n'est pas toujours la même.
:::

```{r}
#Les recettes
rec1 <- 
  recipe(Y_REVENU ~ ., data = train_grandile) 
```

```{r}

#les modèles

#modèle de regression linéaire
mod_lr <- linear_reg() %>% 
  set_engine("lm")

mod_tree <- 
  mod_tree <- 
  decision_tree(
    cost_complexity = 0.02,
    # tree_depth = 7,
    # min_n = NULL
  ) %>%
  set_engine("rpart") %>%
  set_mode("regression")

```

## Modèle 1 : Régression linéaire

```{r}
wflow <- workflow() %>% 
  add_recipe(rec1) %>% 
  add_model(mod_lr)

fit_lr <- wflow %>% fit(data=train_grandile)
fit_lr


```

::: notes
C'est le résultat de l'ajustement de la régression linéaire sur la base d'entraînement : on a donc trois coefficients, qu'on utilisera pour prédire.

On peut déjà avoir des indicateurs de qualité du modèle avec les estimations (cf module de stat sur la modélisation).
:::

## Modèle 2 : Arbre de régression (visualisation) {.smaller}

```{r}
arbre1 <- rpart(Y_REVENU ~ .,data=train_grandile,cp=0.02) 
rpart.plot(arbre1)
```

::: notes
Les cercles représentent une partie de la population d'étude. Le première cercle est appelé la racine,
:::



## Modèle 2 : sortie R

```{r}
wflow <- workflow() %>% 
  add_recipe(rec1) %>% 
  add_model(mod_tree)

fit_tree <- wflow %>% fit(data=train_grandile)
fit_tree

```

## Prévisions sur la base de validation {.scrollable}

```{r}
pred_modele1 <- augment(fit_lr, valid_grandile) %>% select(-`.resid`) %>% rename(Y_REG = `.pred`)
pred_modele2 <- augment(fit_tree,valid_grandile) %>% rename(Y_ARBRE = `.pred`) %>% select(Y_ARBRE) 
pred <- pred_modele2 %>% cbind(pred_modele1) %>% round() %>% select(Y_REVENU,X1_NBPIECES,X2_AGE,Y_REG,Y_ARBRE)
kbl(pred)
```

## Comparaison des performances

| [Modèle]{.underline}               |                        [MSE]{.underline}                         |                           [RMSE]{.underline}                           |                                 [R²]{.underline}                                  |
|------------------|:----------------:|:----------------:|:-----------------:|
| **Modèle 1 : Régression linéaire** |  `r sum((pred$Y_REVENU - pred$Y_REG)^2)/nrow(pred) %>% round()`  |  `r sqrt(sum((pred$Y_REVENU - pred$Y_REG)^2)/nrow(pred)) %>% round()`  |  `r rsq(pred,Y_REVENU,Y_REG) %>% select(.estimate) %>% as.numeric()%>% round(2)`  |
| **Modèle 2 : Arbre**               | `r sum((pred$Y_REVENU - pred$Y_ARBRE)^2)/nrow(pred) %>% round()` | `r sqrt(sum((pred$Y_REVENU - pred$Y_ARBRE)^2)/nrow(pred)) %>% round()` | `r rsq(pred,Y_REVENU,Y_ARBRE) %>% select(.estimate) %>% as.numeric()%>% round(2)` |

## Les critères de choix

1.  Performance du modèle

2.  Contraintes techniques

3.  Interprétabilité

## Entraînement du modèle final

```{r}
fit_tree_final <- wflow %>% fit(data=train_valid_grandile)
fit_tree_final
```

## Généralisation/Mise en production {.scrollable}

```{r}
pred_modele_final <- augment(fit_tree_final, test_grandile) %>% select(-`.resid`,-Y_REVENU) %>% rename(Y_PREVU = `.pred`) %>% round()
kbl(head(pred_modele_final,100))
```

# Deuxième exemple

## Régression ou classification ? {.scrollable}

```{r}

grandile <- asta::grandile %>%
select(Y_PAUVRE = PAUVRE, X1_REVENU = REV_DISPONIBLE, X2_DIPL = DIPL) %>% 
mutate(Y_PAUVRE = as.factor(Y_PAUVRE), X2_DIPL = as.factor(X2_DIPL))

kbl(head(grandile,100))

```

## Exploration de la base brute {.scrollable}

```{r}
# summary(grandile)
summary(grandile)
```

## Partition

![](training-validation-test-sets.png){fig-align="center"}

-   Base d'entraînement : 60 %

-   Base de validation : 20 %

-   Base de test : 20 %

## Exploration de la base d'entraînement {.scrollable}

```{r}
part_training <- 0.6 
part_validation <- 0.2
set.seed(1234)

grandile_split <- initial_validation_split(grandile,
                                            prop = c(part_training,part_validation),
                                            strata = Y_PAUVRE)

train_grandile <- training(grandile_split) #le fichier d'entraînement
test_grandile <- testing(grandile_split) #le fichier de test
valid_grandile <- validation(grandile_split)
train_valid_grandile <- train_grandile %>% bind_rows(valid_grandile)
```

```{r}
summary(train_grandile)
nrow(train_grandile)
```

```{r}
rec1 <- 
  recipe(Y_PAUVRE ~ ., data = train_grandile) 
# %>% step_normalize(all_numeric_predictors()) 
# %>% step_dummy(all_nominal_predictors()) %>% #: pour transformer les variables nominales en indicatrices
# %>% update_role(flight, time_hour, new_role = "ID") %>% #: pour retirer des variables du modèle
# %>%step_normalize(all_numeric_predictors()) #pour centrer réduire
# %>% step_zv() #pour enlever les variables avec une seules valeur
# %>% step_rm() #removes variables
# %>% step_impute_mode() #imputation des valeurs manquantes avec le mode
# %>% step_impute_mean() #imputation des valeurs manquates avec la moyenne
# %>% step_clean_names #nettoyer le nom des variables
```

## Modèles à entraîner

```{r}
mod_lr <- 
  logistic_reg() %>% 
  set_engine("glm")

mod_rf <- 
  rand_forest(trees = 1000,
              mtry = 3,
              min_n = NULL) %>% 
  set_engine("ranger") %>% 
  set_mode("classification")


mod_tree <- 
  mod_tree <- 
  decision_tree(
    cost_complexity = 0.02,
    tree_depth = 7,
    min_n = NULL
  ) %>%
  set_engine("rpart") %>%
  set_mode("classification")
```

-   Régression logistique

-   Arbre de classification

-   Forêt aléatoire

## Modèle 1 : régression logistique

```{r}
wflow <- workflow() %>% 
  add_recipe(rec1) %>% 
  add_model(mod_lr)

fit_lr <- wflow %>% fit(data=train_grandile)
fit_lr
```

## Prévisions (Régression logistique) {.scrollable}

```{r}
pred_valid <- augment(fit_lr, valid_grandile) %>% 
select(Y_PAUVRE,starts_with(".pred")) %>% 
mutate_if(is.numeric,round,digits=2) %>% 
rename(`Y_REG`=`.pred_class`)
kbl(head(pred_valid,100))
```

## Table de confusion (Régression logistique)

```{r}
pred_valid %>%
  conf_mat(Y_PAUVRE, Y_REG) %>%
  autoplot(type="heatmap")
```

## Performance (Régression logistique)

```{r}
#Accuracy : pourcentage de biens classés
accuracy_reg <- pred_valid %>% 
  accuracy(truth = Y_PAUVRE, Y_REG) %>% as.numeric() %>% round(2)

#Spécificité
spec_reg <- pred_valid %>% 
  specificity(truth = Y_PAUVRE, Y_REG) %>% as.numeric() %>% round(2)

#Sensitivité
sens_reg <- pred_valid %>% 
  sensitivity(truth = Y_PAUVRE, Y_REG) %>% as.numeric() %>% round(2)
```

|                                  | Exactitude          | Spécificité     | Sensibilité     |
|-------------------|------------------|------------------|------------------|
| Modèle 1 : régression logistique | `r accuracy_reg[3]` | `r spec_reg[3]` | `r sens_reg[3]` |

## Modèle 2 : arbre de classification

```{r}
wflow <- workflow() %>% 
  add_recipe(rec1) %>% 
  add_model(mod_tree)

fit_tree <- wflow %>% fit(data=train_grandile)
fit_tree

```

```{r}
pred_tree <- augment(fit_tree, valid_grandile) %>% 
select(`.pred_class`) %>% 
mutate_if(is.numeric,round,digits=2) %>% 
rename(`Y_ARBRE`=`.pred_class`)

```

## Modèle 3 : forêt aléatoire

```{r}
wflow <- workflow() %>% 
  add_recipe(rec1) %>% 
  add_model(mod_rf)

fit_rf <- wflow %>% fit(data=train_grandile)
fit_rf
```

```{r}
pred_rf <- augment(fit_rf, valid_grandile) %>% 
select(`.pred_class`) %>% 
mutate_if(is.numeric,round,digits=2) %>% 
rename(`Y_FORET`=`.pred_class`)

```

## Comparaison des modèles

```{r}
pred_valid <- pred_valid %>% bind_cols(pred_tree) %>% bind_cols(pred_rf) %>% select(starts_with("Y"))

#indicateurs pour les arbres

accuracy_tree <- pred_valid %>% 
  accuracy(truth = Y_PAUVRE, Y_ARBRE) %>% as.numeric() %>% round(2)
spec_tree <- pred_valid %>% 
  specificity(truth = Y_PAUVRE, Y_ARBRE) %>% as.numeric() %>% round(2)
sens_tree <- pred_valid %>% 
  sensitivity(truth = Y_PAUVRE, Y_ARBRE) %>% as.numeric() %>% round(2)

#Indicateurs pour les forêts
accuracy_rf <- pred_valid %>% 
  accuracy(truth = Y_PAUVRE, Y_FORET) %>% as.numeric() %>% round(2)
spec_rf <- pred_valid %>% 
  specificity(truth = Y_PAUVRE, Y_FORET) %>% as.numeric() %>% round(2)
sens_rf <- pred_valid %>% 
  sensitivity(truth = Y_PAUVRE, Y_FORET) %>% as.numeric() %>% round(2)

```

|                                    | Exactitude           | Spécificité      | Sensibilité      |
|-------------------|------------------|------------------|------------------|
| Modèle 1 : régression logistique   | `r accuracy_reg[3]`  | `r spec_reg[3]`  | `r sens_reg[3]`  |
| Modèle 2 : arbre de classification | `r accuracy_tree[3]` | `r spec_tree[3]` | `r sens_tree[3]` |
| Modèle 3 : forêt aléatoire         | `r accuracy_rf[3]`   | `r spec_rf[3]`   | `r sens_rf[3]`   |

<!-- ## Apprentissage avec la regression linéaire -->

<!-- ::: columns -->

<!-- ::: {.column width="60%"} -->

<!-- ```{r} -->

<!-- locations <- data.frame(Y_prix = c(1000,800,600,1000,800),X_surface = c(50,30,25,60,35)) -->

<!-- row.names(locations) <- c("logement1","logement2","logement3","logement4","logement5") -->

<!-- reg <- lm(locations$Y_prix ~ locations$X_surface) -->

<!-- kbl(locations, -->

<!--     format = "html") -->

<!-- ``` -->

<!-- ::: -->

<!-- ::: {.column width="40%"} -->

<!-- Par MCO, on trouve la fonction f : -->

<!-- $$ -->

<!-- Y = 416,5 + 10,6 X -->

<!-- $$ -->

<!-- ::: -->

<!-- ::: -->

<!-- ::: notes -->

<!-- Exemple : sur cette base avec une seule variable explicative, par la méthode des MCO (méthode des moindres carrés ordinaires), on peut trouver une droite qui passe au plus près des points du nuage de point (cf module sur les régressions linéaires). -->

<!-- ::: -->

<!-- ## Non supervisé VS supervisé -->

<!-- ::: panel-tabset -->

<!-- ## Non supervisé -->

<!-- ```{r} -->

<!-- locations <- data.frame( -->

<!--                         X1_surface = c(50,30,25,60,35), -->

<!--                         X2_pieces = c(3,2,1,4,1)) -->

<!-- kbl(locations, -->

<!--     format = "html") -->

<!-- ``` -->

<!-- ## Supervisé -->

<!-- ```{r} -->

<!-- locations <- data.frame(Y_prix = c(1000,800,600,1000,800), -->

<!--                         X1_surface = c(50,30,25,60,35), -->

<!--                         X2_pieces = c(3,2,1,4,1)) -->

<!-- kbl(locations, -->

<!--     format = "html") -->

<!-- ``` -->

<!-- ::: -->

<!-- ::: notes -->

<!-- En apprentissage non supervisée, les données ne sont pas étiquetées. Le but est de regrouper automatiquement les individus qui se ressemblent, et de leur trouver ensuite un nom qui les rassemblent : par exemple les grands logements vont être ensemble. Permet de faire de la classification automatique. En apprentissage supervisé, j'ai des données étiquetées (avec un Y) et le but est d'être capable de prédire Y à partir de ces données étiquetées. -->

<!-- ::: -->
