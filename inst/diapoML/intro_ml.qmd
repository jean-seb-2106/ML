---
title: "Introduction au machine learning"
format: 
  revealjs:
    incremental: true
editor: visual
---

```{r}
library(kableExtra)
library(dplyr)
```

## C'est quoi l'intelligence artificielle ?

![](IA_ML.png){fig-align="center"}

::: notes
L'intelligence artificielle définie par Yann le Cun [@Cun2019] : *l'intelligence artificielle est la capacité pour une machine d'assurer des tâches généralement assurée par les animaux ou les humains : percevoir, raisonner, agir.*




:::

## "La bonne vieille IA"...

![](système_expert.png){fig-align="center"}

:::notes
Il y a "la bonne vieille intelligence artificielle" en français, celle pour laquelle un expert explicite toutes les règles qui sont ensuite traduites en langue informatique. Il faut l'expert à côté de l'informaticien qui code, pour lui donner toutes les règles.

C'est celle qu'on utilise depuis longtemps, depuis les années 50.
:::

## ...VS l'apprentissage automatique

![](machine-learning-entrainement-ia.jpg){fig-align="center"}
:::notes
Avec le machine learning, on donne à la machine une grande quantité de donnée, et elle va trouver 'toute seule' cette règle, c'est pour ça qu'on dit qu'elle apprend. Elle apprend grace à un algorithme qui permet de traiter une (très) grande quantité de donnée pour en faire ressortir un schéma réccurent.
:::

## et le Deep learning

![](reseau_neurones.jpg){fig-align="center"}
:::notes
Le deep learning est un sous domaine du machine learning : globalement, il veut reproduire le cerveau humain grace à des neurones articifiels. très puissant en reconnaissance d'images par exemple.
:::

## Les différents types d'apprentissage automatique

1.  L'apprentissage supervisé

2.  L'apprentissage non supervisé

3.  L'apprentissage par essai/erreur

## Non supervisé VS supervisé

::: panel-tabset
## Non supervisé

```{r}
locations <- data.frame(
                        X1_surface = c(50,30,25,60,35),
                        X2_pieces = c(3,2,1,4,1))

kbl(locations,
    format = "html")
```

## Supervisé

```{r}
locations <- data.frame(Y_prix = c(1000,800,600,1000,800),
                        X1_surface = c(50,30,25,60,35),
                        X2_pieces = c(3,2,1,4,1))

kbl(locations,
    format = "html")
```
:::

::: notes
En apprentissage non supervisée, les données ne sont pas étiquetées. Le but est de regrouper automatiquement les individus qui se ressemblent, et de leur trouver ensuite un nom qui les rassemblent : par exemple les grands logements vont être ensemble. Permet de faire de la classification automatique. En apprentissage supervisé, j'ai des données étiquetées (avec un Y) et le but est d'être capable de prédire Y à partir de ces données étiquetées.
:::

## But de l'apprentissage supervisé

Il s'agit de trouver la fonction f qui va le mieux **prédire** Y en fonction de X1, X2...,Xn

$$
Y = f(X_1, X_2, ...,X_n)
$$

## Les étapes de l'apprentissage supervisé :

1.  Disposer d'une base de données étiquetée

2.  Nettoyer et explorer cette base de données

3.  Réserver une partie de la base pour l'apprentissage/test

4.  Apprendre des données avec des algorithmes

5.  Comparer les performances prédictives de ces algorithmes

6.  Choisir le meilleur modèle et le mettre en production


## Apprentissage avec la regression linéaire

::: columns
::: {.column width="60%"}
```{r}
locations <- data.frame(Y_prix = c(1000,800,600,1000,800),X_surface = c(50,30,25,60,35))
row.names(locations) <- c("logement1","logement2","logement3","logement4","logement5")
reg <- lm(locations$Y_prix ~ locations$X_surface)
kbl(locations,
    format = "html")
```
:::

::: {.column width="40%"}
Par MCO, on trouve la fonction f :

$$
Y = 416,5 + 10,6 X
$$
:::
:::

::: notes
Exemple : sur cette base avec une seule variable explicative, par la méthode des MCO (méthode des moindres carrés ordinaires), on peut trouver une droite qui passe au plus près des points du nuage de point (cf module sur les régressions linéaires).
:::

## Estimations ou prévisions ?

::: panel-tabset
## Estimations

```{r}
locations <- data.frame(prix = c(1000,800,600,1000,800),surface = c(50,30,25,60,35))
row.names(locations) <- c("logement1","logement2","logement3","logement4","logement5")
reg <- lm(locations$prix ~ locations$surface)
locations$prix_estime <- predict(reg)
kbl(locations,
    format = "html")
```

## Prévisions

```{r}
locations <- data.frame(surface = c(45,30,110))
row.names(locations) <- c("logement6","logement7","logement8")



locations <- locations %>% 
  mutate(prix_prevu = reg$coefficients[1] + reg$coefficients[2]*surface)
kbl(locations,format = "html")

```
:::
